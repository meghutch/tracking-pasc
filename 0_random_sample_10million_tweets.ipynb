{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hydration of Tweets\n",
    "July 8, 2022\n",
    "\n",
    "This notebook first imports the no_retweets_set_filtered.tsv file which contains all of the non-retweet data from the Pancaea Lab, version 120 which was uploaded on June 26, 2022 (https://zenodo.org/record/6758164) \n",
    "\n",
    "This notebook will randomly sample 10,000,000 tweets from the > 190,000,000 available tweets. \n",
    "\n",
    "Anish M. already randomly selected 120,000 tweets and so we will make sure to exclude those from our 10 million list. \n",
    "\n",
    "This list of tweets will then be hydrated to support of PASC tweet topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"../data/no_retweets_set_filtered.tsv\", delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, we will remove the 120,000 tweets that Anish has already hydrated**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydrated_tweets = pd.read_csv(\"../data/test.txt\")\n",
    "print(len(hydrated_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydrated_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydrated_tweets_list = hydrated_tweets['tweet_id']\n",
    "hydrated_tweets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tweets))\n",
    "tweets = tweets[~tweets.tweet_id.isin(hydrated_tweets_list)]\n",
    "print(len(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "190561814-len(tweets )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[['tweet_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['tweet_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[tweets['tweet_id'] == 1485085282370269188]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's make sure to remove duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tweets))\n",
    "tweets = tweets.drop_duplicates()\n",
    "print(len(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "190441795-190418594"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomly sample 10,000,000 tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(232)\n",
    "random_sample_tweets = random.sample(range(len(tweets)), 10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample_tweets[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tweets = tweets.iloc[random_sample_tweets]\n",
    "len(sample_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tweets[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check that the distribution of tweets remained the same**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[['tweet_id']].groupby([tweets[\"date\"].dt.year, tweets[\"date\"].dt.month]).count().plot(kind=\"bar\")\n",
    "sample_tweets[['tweet_id']].groupby([sample_tweets[\"date\"].dt.year, sample_tweets[\"date\"].dt.month]).count().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tweets[\"tweet_id\"].to_csv('10_million_tweets.txt', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid-dtm",
   "language": "python",
   "name": "covid-dtm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
