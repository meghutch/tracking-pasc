{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mon Jan 27 21:16:47 +0000 2020</td>\n",
       "      <td>Coronavirus is just Ebola 2.</td>\n",
       "      <td>Coronavirus is just Ebola 2</td>\n",
       "      <td>coronavirus is just ebola 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mon Jan 27 18:36:22 +0000 2020</td>\n",
       "      <td>Not much being said about the massive roll out of #5G in  #Wuhan in 2019 - a radiating technology that easily can affect microscopic life in certain ranges.  #coronavirus \\nhttps://t.co/7FmjXiq3Ds</td>\n",
       "      <td>Not much being said about the massive roll out of 5G in  Wuhan in 2019  a radiating technology that easily can affect microscopic life in certain ranges  coronavirus \\nhttpstco7FmjXiq3Ds</td>\n",
       "      <td>not much being said about the massive roll out of 5g in  wuhan in 2019  a radiating technology that easily can affect microscopic life in certain ranges  coronavirus \\nhttpstco7fmjxiq3ds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue Jan 28 09:34:16 +0000 2020</td>\n",
       "      <td>Moscow imposes special safety measures at tourist sites over coronavirus fears\\nSource: Reuters\\nhttps://t.co/QizM35Lyi7</td>\n",
       "      <td>Moscow imposes special safety measures at tourist sites over coronavirus fears\\nSource Reuters\\nhttpstcoQizM35Lyi7</td>\n",
       "      <td>moscow imposes special safety measures at tourist sites over coronavirus fears\\nsource reuters\\nhttpstcoqizm35lyi7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon Jan 27 20:07:17 +0000 2020</td>\n",
       "      <td>life in #Wuhan after #coronavirus 2\\n\\nhttps://t.co/qd445iqqmW</td>\n",
       "      <td>life in Wuhan after coronavirus 2\\n\\nhttpstcoqd445iqqmW</td>\n",
       "      <td>life in wuhan after coronavirus 2\\n\\nhttpstcoqd445iqqmw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tue Jan 28 11:50:19 +0000 2020</td>\n",
       "      <td>Japan confirms coronavirus in man with no recent travel to China https://t.co/ZRDXaofOLm https://t.co/nHg1qThY9t</td>\n",
       "      <td>Japan confirms coronavirus in man with no recent travel to China httpstcoZRDXaofOLm httpstconHg1qThY9t</td>\n",
       "      <td>japan confirms coronavirus in man with no recent travel to china httpstcozrdxaofolm httpstconhg1qthy9t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "0  Mon Jan 27 21:16:47 +0000 2020   \n",
       "1  Mon Jan 27 18:36:22 +0000 2020   \n",
       "2  Tue Jan 28 09:34:16 +0000 2020   \n",
       "3  Mon Jan 27 20:07:17 +0000 2020   \n",
       "4  Tue Jan 28 11:50:19 +0000 2020   \n",
       "\n",
       "                                                                                                                                                                                                   text  \\\n",
       "0  Coronavirus is just Ebola 2.                                                                                                                                                                           \n",
       "1  Not much being said about the massive roll out of #5G in  #Wuhan in 2019 - a radiating technology that easily can affect microscopic life in certain ranges.  #coronavirus \\nhttps://t.co/7FmjXiq3Ds   \n",
       "2  Moscow imposes special safety measures at tourist sites over coronavirus fears\\nSource: Reuters\\nhttps://t.co/QizM35Lyi7                                                                               \n",
       "3  life in #Wuhan after #coronavirus 2\\n\\nhttps://t.co/qd445iqqmW                                                                                                                                         \n",
       "4  Japan confirms coronavirus in man with no recent travel to China https://t.co/ZRDXaofOLm https://t.co/nHg1qThY9t                                                                                       \n",
       "\n",
       "                                                                                                                                                                                   clean_text  \\\n",
       "0  Coronavirus is just Ebola 2                                                                                                                                                                  \n",
       "1  Not much being said about the massive roll out of 5G in  Wuhan in 2019  a radiating technology that easily can affect microscopic life in certain ranges  coronavirus \\nhttpstco7FmjXiq3Ds   \n",
       "2  Moscow imposes special safety measures at tourist sites over coronavirus fears\\nSource Reuters\\nhttpstcoQizM35Lyi7                                                                           \n",
       "3  life in Wuhan after coronavirus 2\\n\\nhttpstcoqd445iqqmW                                                                                                                                      \n",
       "4  Japan confirms coronavirus in man with no recent travel to China httpstcoZRDXaofOLm httpstconHg1qThY9t                                                                                       \n",
       "\n",
       "                                                                                                                                                                                   text_lower  \n",
       "0  coronavirus is just ebola 2                                                                                                                                                                 \n",
       "1  not much being said about the massive roll out of 5g in  wuhan in 2019  a radiating technology that easily can affect microscopic life in certain ranges  coronavirus \\nhttpstco7fmjxiq3ds  \n",
       "2  moscow imposes special safety measures at tourist sites over coronavirus fears\\nsource reuters\\nhttpstcoqizm35lyi7                                                                          \n",
       "3  life in wuhan after coronavirus 2\\n\\nhttpstcoqd445iqqmw                                                                                                                                     \n",
       "4  japan confirms coronavirus in man with no recent travel to china httpstcozrdxaofolm httpstconhg1qthy9t                                                                                      "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "sample_tweets = pd.read_csv(\"test_tweets.csv\")\n",
    "stripped_sample_tweets = sample_tweets[[\"created_at\", \"text\"]]\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "stripped_sample_tweets['clean_text']= stripped_sample_tweets['text'].apply(lambda x:remove_punctuation(x))\n",
    "stripped_sample_tweets['text_lower']= stripped_sample_tweets['clean_text'].apply(lambda x: x.lower())\n",
    "stripped_sample_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coronavirus is just ebola 2',\n",
       " 'not much being said about the massive roll out of 5g in  wuhan in 2019  a radiating technology that easily can affect microscopic life in certain ranges  coronavirus \\nhttpstco7fmjxiq3ds',\n",
       " 'moscow imposes special safety measures at tourist sites over coronavirus\\xa0fears\\nsource reuters\\nhttpstcoqizm35lyi7',\n",
       " 'life in wuhan after coronavirus 2\\n\\nhttpstcoqd445iqqmw',\n",
       " 'japan confirms coronavirus in man with no recent travel to\\xa0china httpstcozrdxaofolm httpstconhg1qthy9t',\n",
       " 'lyndseylda abbythetweet especially now with that coronavirus all over the news everyones getting spraued with lysol lol',\n",
       " 'news health secretary matt hancock says people who have returned to the uk from wuhan in china in the last 14 days should selfisolate even if they have no symptoms of the coronavirus httpstcoublhikpeic',\n",
       " 'china delays restart of schools universities over virus concerns source coronavirus\\ncgnews connectgujarat beyondjustnews',\n",
       " 'coronavirus china postpones school semester death toll jumps to 106 httpstcokg5kjubrqn',\n",
       " 'wife of canadas first coronavirus patient tests positive 19 under investigation httpstcogsflp5sgcl httpstcojbz96dlpsj']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_list = []\n",
    "\n",
    "for text in stripped_sample_tweets[\"text_lower\"]:\n",
    "    tweets_list.append(text)\n",
    "\n",
    "tweets_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "topic_model = BERTopic()\n",
    "topics, probs = topic_model.fit_transform(tweets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>45311</td>\n",
       "      <td>-1_the_to_and_this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2244</td>\n",
       "      <td>0_mask_masks_wear_wearing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2046</td>\n",
       "      <td>1_china_chinese_wuhan_chinas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1432</td>\n",
       "      <td>2_schools_school_students_education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1105</td>\n",
       "      <td>3_coronavirus_gramblingrys20_mutation_novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>681</td>\n",
       "      <td>10</td>\n",
       "      <td>681_morale_punishment_deathparty_miseducated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>682</td>\n",
       "      <td>10</td>\n",
       "      <td>682_nj_jersey_newjersey_httpstcoinf3cnjool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>683</td>\n",
       "      <td>10</td>\n",
       "      <td>683_thanks_latest_ambulant_httpstcoaawmusc8h0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>684</td>\n",
       "      <td>10</td>\n",
       "      <td>684_israel_becos_israeli_mampos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>685</td>\n",
       "      <td>10</td>\n",
       "      <td>685_record_httpstcotysyxvaqsn_httpstcoedocjrnsoz_httpstcoaleordcic5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>687 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count  \\\n",
       "0   -1      45311   \n",
       "1    0      2244    \n",
       "2    1      2046    \n",
       "3    2      1432    \n",
       "4    3      1105    \n",
       "..  ..       ...    \n",
       "675  681    10      \n",
       "674  682    10      \n",
       "673  683    10      \n",
       "672  684    10      \n",
       "686  685    10      \n",
       "\n",
       "                                                                    Name  \n",
       "0    -1_the_to_and_this                                                   \n",
       "1    0_mask_masks_wear_wearing                                            \n",
       "2    1_china_chinese_wuhan_chinas                                         \n",
       "3    2_schools_school_students_education                                  \n",
       "4    3_coronavirus_gramblingrys20_mutation_novel                          \n",
       "..                                           ...                          \n",
       "675  681_morale_punishment_deathparty_miseducated                         \n",
       "674  682_nj_jersey_newjersey_httpstcoinf3cnjool                           \n",
       "673  683_thanks_latest_ambulant_httpstcoaawmusc8h0                        \n",
       "672  684_israel_becos_israeli_mampos                                      \n",
       "686  685_record_httpstcotysyxvaqsn_httpstcoedocjrnsoz_httpstcoaleordcic5  \n",
       "\n",
       "[687 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mon Jan 27 21:16:47 +0000 2020</td>\n",
       "      <td>Coronavirus is just Ebola 2.</td>\n",
       "      <td>[coronavirus, ebola, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mon Jan 27 18:36:22 +0000 2020</td>\n",
       "      <td>Not much being said about the massive roll out of #5G in  #Wuhan in 2019 - a radiating technology that easily can affect microscopic life in certain ranges.  #coronavirus \\nhttps://t.co/7FmjXiq3Ds</td>\n",
       "      <td>[much, said, massive, roll, 5g, wuhan, 2019, radiating, technology, easily, affect, microscopic, life, certain, range, coronavirus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue Jan 28 09:34:16 +0000 2020</td>\n",
       "      <td>Moscow imposes special safety measures at tourist sites over coronavirus fears\\nSource: Reuters\\nhttps://t.co/QizM35Lyi7</td>\n",
       "      <td>[moscow, imposes, special, safety, measure, tourist, site, coronavirus, fear, source, reuters]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mon Jan 27 20:07:17 +0000 2020</td>\n",
       "      <td>life in #Wuhan after #coronavirus 2\\n\\nhttps://t.co/qd445iqqmW</td>\n",
       "      <td>[life, wuhan, coronavirus, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tue Jan 28 11:50:19 +0000 2020</td>\n",
       "      <td>Japan confirms coronavirus in man with no recent travel to China https://t.co/ZRDXaofOLm https://t.co/nHg1qThY9t</td>\n",
       "      <td>[japan, confirms, coronavirus, man, recent, travel, china, httpstconhg1qthy9t]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "0  Mon Jan 27 21:16:47 +0000 2020   \n",
       "1  Mon Jan 27 18:36:22 +0000 2020   \n",
       "2  Tue Jan 28 09:34:16 +0000 2020   \n",
       "3  Mon Jan 27 20:07:17 +0000 2020   \n",
       "4  Tue Jan 28 11:50:19 +0000 2020   \n",
       "\n",
       "                                                                                                                                                                                                   text  \\\n",
       "0  Coronavirus is just Ebola 2.                                                                                                                                                                           \n",
       "1  Not much being said about the massive roll out of #5G in  #Wuhan in 2019 - a radiating technology that easily can affect microscopic life in certain ranges.  #coronavirus \\nhttps://t.co/7FmjXiq3Ds   \n",
       "2  Moscow imposes special safety measures at tourist sites over coronavirus fears\\nSource: Reuters\\nhttps://t.co/QizM35Lyi7                                                                               \n",
       "3  life in #Wuhan after #coronavirus 2\\n\\nhttps://t.co/qd445iqqmW                                                                                                                                         \n",
       "4  Japan confirms coronavirus in man with no recent travel to China https://t.co/ZRDXaofOLm https://t.co/nHg1qThY9t                                                                                       \n",
       "\n",
       "                                                                                                                       text_lemmatized  \n",
       "0  [coronavirus, ebola, 2]                                                                                                              \n",
       "1  [much, said, massive, roll, 5g, wuhan, 2019, radiating, technology, easily, affect, microscopic, life, certain, range, coronavirus]  \n",
       "2  [moscow, imposes, special, safety, measure, tourist, site, coronavirus, fear, source, reuters]                                       \n",
       "3  [life, wuhan, coronavirus, 2]                                                                                                        \n",
       "4  [japan, confirms, coronavirus, man, recent, travel, china, httpstconhg1qthy9t]                                                       "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def tokenization(text):\n",
    "    tokens = re.split(r'\\W+', text)\n",
    "    return tokens\n",
    "\n",
    "def remove_http(string_list):\n",
    "    for string in string_list:\n",
    "        if string[:4] == \"http\":\n",
    "            string_list.remove(string)\n",
    "    return string_list\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    output= [i for i in text if i not in stopwords]\n",
    "    return output\n",
    "\n",
    "def stemming(text):\n",
    "    stem_text = [porter_stemmer.stem(word) for word in text]\n",
    "    return stem_text\n",
    "\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text\n",
    "\n",
    "stripped_sample_tweets['text_tokenied']= stripped_sample_tweets['text_lower'].apply(lambda x: tokenization(x))\n",
    "stripped_sample_tweets['text_full_tokenied']= stripped_sample_tweets['text_tokenied'].apply(lambda x: remove_http(x))\n",
    "stripped_sample_tweets['no_stopwords']= stripped_sample_tweets['text_full_tokenied'].apply(lambda x:remove_stopwords(x))\n",
    "stripped_sample_tweets['text_lemmatized'] = stripped_sample_tweets['no_stopwords'].apply(lambda x:lemmatizer(x))\n",
    "stripped_sample_tweets = stripped_sample_tweets[['created_at', 'text', 'text_lemmatized']]\n",
    "stripped_sample_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['coronavirus', 'ebola', '2'],\n",
       " ['much',\n",
       "  'said',\n",
       "  'massive',\n",
       "  'roll',\n",
       "  '5g',\n",
       "  'wuhan',\n",
       "  '2019',\n",
       "  'radiating',\n",
       "  'technology',\n",
       "  'easily',\n",
       "  'affect',\n",
       "  'microscopic',\n",
       "  'life',\n",
       "  'certain',\n",
       "  'range',\n",
       "  'coronavirus'],\n",
       " ['moscow',\n",
       "  'imposes',\n",
       "  'special',\n",
       "  'safety',\n",
       "  'measure',\n",
       "  'tourist',\n",
       "  'site',\n",
       "  'coronavirus',\n",
       "  'fear',\n",
       "  'source',\n",
       "  'reuters'],\n",
       " ['life', 'wuhan', 'coronavirus', '2']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_list = []\n",
    "\n",
    "for words in stripped_sample_tweets[\"text_lemmatized\"]:\n",
    "    tweets_list.append(words)\n",
    "\n",
    "tweets_list[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Make sure that the iterable only contains strings.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m topic_model \u001b[38;5;241m=\u001b[39m BERTopic()\n\u001b[0;32m----> 2\u001b[0m topics, probs \u001b[38;5;241m=\u001b[39m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtweets_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/my-virtenv-py38/lib/python3.8/site-packages/bertopic/_bertopic.py:283\u001b[0m, in \u001b[0;36mBERTopic.fit_transform\u001b[0;34m(self, documents, embeddings, y)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    234\u001b[0m                   documents: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    235\u001b[0m                   embeddings: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    236\u001b[0m                   y: Union[List[\u001b[38;5;28mint\u001b[39m], np\u001b[38;5;241m.\u001b[39mndarray] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    237\u001b[0m                                                                    Union[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28;01mNone\u001b[39;00m]]:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;124;03m\"\"\" Fit the models on a collection of documents, generate topics, and return the docs with topics\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m    Arguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     \u001b[43mcheck_documents_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m     check_embeddings_shape(embeddings, documents)\n\u001b[1;32m    286\u001b[0m     documents \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument\u001b[39m\u001b[38;5;124m\"\u001b[39m: documents,\n\u001b[1;32m    287\u001b[0m                               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(documents)),\n\u001b[1;32m    288\u001b[0m                               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTopic\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m})\n",
      "File \u001b[0;32m~/.conda/envs/my-virtenv-py38/lib/python3.8/site-packages/bertopic/_utils.py:36\u001b[0m, in \u001b[0;36mcheck_documents_type\u001b[0;34m(documents)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(documents, Iterable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(documents, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m([\u001b[38;5;28misinstance\u001b[39m(doc, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]):\n\u001b[0;32m---> 36\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure that the iterable only contains strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure that the documents variable is an iterable containing strings only.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Make sure that the iterable only contains strings."
     ]
    }
   ],
   "source": [
    "topic_model = BERTopic()\n",
    "topics, probs = topic_model.fit_transform(tweets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Environment",
   "language": "python",
   "name": "my-virtenv-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
