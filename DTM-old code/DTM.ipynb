{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import re\n",
    "\n",
    "import logging\n",
    "#import yaml\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string \n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import corpora\n",
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.wrappers import DtmModel\n",
    "from gensim import matutils\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import logging.config\n",
    "\n",
    "# configure logging\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set working directory\n",
    "os.chdir(\"/home/mrh1996/LDA_COVID_Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to load data\n",
    "def load_tweet_data(data_path = 'data/constructs.csv'):\n",
    "    \"\"\"Load data from S3 Bucket. \n",
    "\n",
    "    Args:\n",
    "        s3path_str: str - name and path of the S3 bucket.\n",
    "\n",
    "    Returns:\n",
    "        tweet_data: dataframe - dataframe of all the tweets.\n",
    "    \"\"\"    \n",
    "    \n",
    "    logger.debug(\"Load data from path.\")\n",
    "    \n",
    "    tweet_data = pd.read_csv(data_path)\n",
    "    \n",
    "    if len(tweet_data) > 0:\n",
    "        logger.info(\"Dataset was loaded with %s rows\", len(tweet_data))\n",
    "    else: \n",
    "        logger.warning(\"Dataset is empty or did not load correctly!\")\n",
    "    \n",
    "    return tweet_data\n",
    "\n",
    "# function to remove duplicates\n",
    "def remove_duplicates(df):\n",
    "    \"\"\"Remove any rows with duplicate text.\n",
    "    \n",
    "    Args: \n",
    "        df: dataframe of tweet data.\n",
    "        \n",
    "    Returns: \n",
    "        tweet_data: dataframe - dataframe without duplicate text entries.\n",
    "    \"\"\"\n",
    "    \n",
    "    logger.debug(\"Drop duplicate rows.\")\n",
    "    \n",
    "    tweet_data = df.drop_duplicates(subset=['read_text_clean2'], keep='first')\n",
    "    \n",
    "    logger.info(\"%s rows were dropped\", len(df) - len(tweet_data))\n",
    "    \n",
    "    return(tweet_data)\n",
    "\n",
    "# function to format dates\n",
    "def format_dates(df):\n",
    "    \"\"\"Format the 'create_at' data column to contain the month, day, and year only.\n",
    "    \n",
    "    Args: \n",
    "        df: dataframe - dataframe of the tweet_data.\n",
    "        \n",
    "    Returns: \n",
    "        df: dataframe - tweet data with a revised date column.\n",
    "    \"\"\"\n",
    "    \n",
    "    logger.debug(\"Format date column.\")\n",
    "    \n",
    "    df['date'] = df['created_at'].str.split(' ').str[1:3]\n",
    "    df['date'] = df['date'].str.join(' ')\n",
    "    df['date'] = df['date'].astype(str)\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'] + ' 2020', format='%b %d %Y', errors='coerce')\n",
    "    \n",
    "    logger.info(\"New column created.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# function to clean text \n",
    "def clean_text(tweets, stop_words_list, exclude, lemma):\n",
    "    \"\"\"Clean text data by removing punctuation and implementing lemmatization.\n",
    "    \n",
    "    Args:\n",
    "        tweets: dataframe - dataframe subset by time.\n",
    "        stop_words_list: list - list of words to remove from the analysis.\n",
    "        exclude: set - set of non-alphanumeric characters to remove.\n",
    "        lemma: nltk method to lemmatize text.\n",
    "    \n",
    "    Returns:\n",
    "        doc_clean: dataframe - dataframe with processed text.\n",
    "    \"\"\"\n",
    "\n",
    "    logger.debug(\"Begin text processing.\")\n",
    "    \n",
    "    logger.info(\"Tokenize and Remove stop words\")\n",
    "    stop_free = \" \".join([i for i in word_tokenize(tweets) if i not in stop_words_list])\n",
    "    \n",
    "    logger.info(\"Remove punctuation.\")\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    \n",
    "    logger.info(\"Lemmatize words.\")\n",
    "    doc_clean = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    \n",
    "    return doc_clean\n",
    "\n",
    "# function to create document term matrix and dictionary corpus \n",
    "def create_dictionary(df):\n",
    "    \"\"\"Create dictionary and a matrix of the terms per document.\n",
    "    \n",
    "    Args: \n",
    "        df: dataframe - processed dataframe.\n",
    "    \n",
    "    Returns:\n",
    "        dictionary: corpora.dictionary - dictionary mapping each term to it's integer id.\n",
    "        doc_term_matrix: list - bag of words matrix with frequency of each term mapped to dictionary id.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    logger.debug(\"Create dictionary.\")\n",
    "    \n",
    "    dictionary = corpora.Dictionary(df)\n",
    "    \n",
    "    logger.info(\"Dictionary created.\")\n",
    "\n",
    "    logger.debug(\"Create document term matrix.\")\n",
    "    \n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in df]\n",
    "    \n",
    "    logger.info(\"Document term matrix created.\")\n",
    "    \n",
    "    return dictionary, doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes = phecode_vector_clean.groupby('patient_num')['phenotype'].apply(', '.join).reset_index()\n",
    "phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mrh1996/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/mrh1996/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mrh1996/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download nltk sets\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare methods for text processing\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "# create list of stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "alphabet_remove = list(string.ascii_lowercase)\n",
    "number_remove = list(range(0, 9999))\n",
    "number_remove = map(str, number_remove) \n",
    "number_remove = list(number_remove)\n",
    "\n",
    "stop_words_list = stop_words.union(number_remove, alphabet_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5472170790036519\n",
      "Train data: 5585780\n",
      "Test data: 1117156\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Process data\n",
    "tweet_data = pd.read_csv('data/constructs.csv')\n",
    "tweet_data_train, test_data = train_test_split(tweet_data, test_size=0.20, random_state=82121)\n",
    "\n",
    "end = time.time()\n",
    "print((end - start)/60)\n",
    "\n",
    "print('Train data:', len(tweet_data))\n",
    "print('Test data:', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 4468624\n",
      "Test data: 4468624\n"
     ]
    }
   ],
   "source": [
    "print('Train data:', len(tweet_data_train))\n",
    "print('Test data:', len(tweet_data_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Subset data temporality to speed up preliminary analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_data_train = tweet_data#.head(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrh1996/.local/lib/python3.6/site-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/mrh1996/.local/lib/python3.6/site-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/mrh1996/.local/lib/python3.6/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4309366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrh1996/.local/lib/python3.6/site-packages/ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "tweet_data_train = remove_duplicates(tweet_data_train)\n",
    "tweet_data_formatted = format_dates(tweet_data_train)\n",
    "\n",
    "print(len(tweet_data_formatted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>predicted</th>\n",
       "      <th>created_at</th>\n",
       "      <th>read_user_id</th>\n",
       "      <th>read_tweet_id</th>\n",
       "      <th>user_location</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>place</th>\n",
       "      <th>read_text_clean2</th>\n",
       "      <th>Perceived_susceptibility</th>\n",
       "      <th>Perceived_severity</th>\n",
       "      <th>Perceived_benefits</th>\n",
       "      <th>Perceived_barriers</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri Mar 27 18:03:15 +0000 2020</td>\n",
       "      <td>443692189</td>\n",
       "      <td>1243599480177471489</td>\n",
       "      <td>Hyderabad, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yet no , federal lockdown \\? \\? make america g...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri May 01 02:04:45 +0000 2020</td>\n",
       "      <td>529055116</td>\n",
       "      <td>1256041840807206914</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cases of coronavirus has been climbing the las...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Wed Apr 15 19:33:55 +0000 2020</td>\n",
       "      <td>139283160</td>\n",
       "      <td>1250507666956443651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tennessee reports 256 new cases and 11 new dea...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue Jun 16 01:25:11 +0000 2020</td>\n",
       "      <td>999766907468308481</td>\n",
       "      <td>1272701725036679168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>well let s let oklahoma decide they don t have...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri May 22 09:34:30 +0000 2020</td>\n",
       "      <td>4835434534</td>\n",
       "      <td>1263765169055858688</td>\n",
       "      <td>Abuja, Nigeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>please don t be that dismissive of facts coron...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon Jun 08 21:01:38 +0000 2020</td>\n",
       "      <td>48769276</td>\n",
       "      <td>1270098685628682242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nyt breaking news new daily coronavirus cases ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue May 19 21:04:44 +0000 2020</td>\n",
       "      <td>1240761596894416900</td>\n",
       "      <td>1262851706037194754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ohio usa northamerica cases 28 , 956 \\( 1 \\) d...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>Thu Apr 23 09:17:13 +0000 2020</td>\n",
       "      <td>417553124</td>\n",
       "      <td>1253251569253888000</td>\n",
       "      <td>West Coast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roberts failed to understand there are far mor...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>Sat May 30 20:50:36 +0000 2020</td>\n",
       "      <td>88661178</td>\n",
       "      <td>1266834417600933895</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'id': '011a942e0a0e8fb2', 'url': 'https://api...</td>\n",
       "      <td>america coming from a lockdown to utter chaos ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun Apr 26 03:25:02 +0000 2020</td>\n",
       "      <td>85035396</td>\n",
       "      <td>1254250103113691145</td>\n",
       "      <td>🅱🅷🅰🆁🅰🆃</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>total number of covid19 cases rise to 26 , 496...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun May 10 04:34:17 +0000 2020</td>\n",
       "      <td>910586279871614977</td>\n",
       "      <td>1259340963895369728</td>\n",
       "      <td>California, Kern County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the virology journal the official publication ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon Apr 20 05:46:11 +0000 2020</td>\n",
       "      <td>21099818</td>\n",
       "      <td>1252111300265750528</td>\n",
       "      <td>London, England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>help slow the spread of covid19 and identify a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>Thu May 28 15:15:00 +0000 2020</td>\n",
       "      <td>1243652399727771651</td>\n",
       "      <td>1266025183795707910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there have been 10 confirmed cases of covid19 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon May 18 22:03:20 +0000 2020</td>\n",
       "      <td>270921976</td>\n",
       "      <td>1262504067881984000</td>\n",
       "      <td>CANADA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70 cases of covid 19 linked to french schools ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>215</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue May 05 00:22:09 +0000 2020</td>\n",
       "      <td>19898168</td>\n",
       "      <td>1257465569588195329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coronavirus live updates global death toll top...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>Sat May 23 03:20:39 +0000 2020</td>\n",
       "      <td>1232104880220839937</td>\n",
       "      <td>1264033473247031298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>key words fraud , seriously ill covid 19 patie...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun Apr 19 15:53:02 +0000 2020</td>\n",
       "      <td>70244885</td>\n",
       "      <td>1251901631098060800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>japanese hospitals overwhelmed as nation tops ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>259</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri Apr 24 16:01:04 +0000 2020</td>\n",
       "      <td>79983391</td>\n",
       "      <td>1253715591745212418</td>\n",
       "      <td>Lancashire, England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>during the covid 19 lockdown it s important to...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon Apr 13 18:31:40 +0000 2020</td>\n",
       "      <td>2619163263</td>\n",
       "      <td>1249767225692549121</td>\n",
       "      <td>Christian/English USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>share to agree w no more to haters plotting ou...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>327</td>\n",
       "      <td>1</td>\n",
       "      <td>Sat Apr 18 10:51:39 +0000 2020</td>\n",
       "      <td>339277892</td>\n",
       "      <td>1251463398644166659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>united states coronavirus cases 710 , 272 deat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>334</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun Mar 08 11:28:07 +0000 2020</td>\n",
       "      <td>352875784</td>\n",
       "      <td>1236614672112992258</td>\n",
       "      <td>mumbai, india</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>singapore has recorded eight new cases of coro...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon Apr 27 07:23:04 +0000 2020</td>\n",
       "      <td>1096681020</td>\n",
       "      <td>1254672396168151041</td>\n",
       "      <td>Northern Ireland, United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the issue is , if they fail to take action it ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>374</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon May 25 15:28:28 +0000 2020</td>\n",
       "      <td>1245009868563587073</td>\n",
       "      <td>1264941410123427840</td>\n",
       "      <td>Toronto, Ontario</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>covid 19 today gt 14 , 570 , 000 people in ont...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>387</td>\n",
       "      <td>1</td>\n",
       "      <td>Wed May 27 22:47:13 +0000 2020</td>\n",
       "      <td>966846014698283008</td>\n",
       "      <td>1265776602530676736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>interestingly , there has only been one death ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>393</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue May 26 02:32:34 +0000 2020</td>\n",
       "      <td>1084980649520496642</td>\n",
       "      <td>1265108539011485698</td>\n",
       "      <td>New York City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pathological liar , corrupt criminal donaldtru...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>404</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon Feb 17 18:15:28 +0000 2020</td>\n",
       "      <td>914746291753832448</td>\n",
       "      <td>1229469427512565769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chinese doctors 'using plasma therapy' on coro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>405</td>\n",
       "      <td>1</td>\n",
       "      <td>Sat May 02 16:54:02 +0000 2020</td>\n",
       "      <td>971667390994903040</td>\n",
       "      <td>1256628025258467328</td>\n",
       "      <td>Scotland, United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>italy 's daily coronavirus death toll jumps , ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>420</td>\n",
       "      <td>1</td>\n",
       "      <td>Wed Apr 29 17:17:13 +0000 2020</td>\n",
       "      <td>99710686</td>\n",
       "      <td>1255546694768513026</td>\n",
       "      <td>Nowhere Boy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>early peek at data on gilead coronavirus drug ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>427</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon Jun 01 12:13:27 +0000 2020</td>\n",
       "      <td>973724136</td>\n",
       "      <td>1267429046352261121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'id': '6a1b0cb35bcaf140', 'url': 'https://api...</td>\n",
       "      <td>coronavirus dorset hospital death toll rises t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>454</td>\n",
       "      <td>1</td>\n",
       "      <td>Thu Apr 30 09:02:06 +0000 2020</td>\n",
       "      <td>1114553046753792000</td>\n",
       "      <td>1255784483132932096</td>\n",
       "      <td>Melle, België</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>we have finetuned our data flows , and are now...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>472</td>\n",
       "      <td>1</td>\n",
       "      <td>Thu May 07 02:25:06 +0000 2020</td>\n",
       "      <td>34677788</td>\n",
       "      <td>1258221289606709251</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>covid 19 patients wrong to think breathing tub...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>478</td>\n",
       "      <td>1</td>\n",
       "      <td>Wed Apr 22 00:28:58 +0000 2020</td>\n",
       "      <td>312045771</td>\n",
       "      <td>1252756242826592256</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>if only we could track the up to 10 of these f...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>481</td>\n",
       "      <td>1</td>\n",
       "      <td>Thu Apr 09 06:17:00 +0000 2020</td>\n",
       "      <td>61788662</td>\n",
       "      <td>1248132788798144512</td>\n",
       "      <td>Port Moody, British Columbia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'id': '55b2935da16ddb91', 'url': 'https://api...</td>\n",
       "      <td>media just parrots that closing parks will hel...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>484</td>\n",
       "      <td>1</td>\n",
       "      <td>Wed May 06 14:58:01 +0000 2020</td>\n",
       "      <td>12663042</td>\n",
       "      <td>1258048378543509504</td>\n",
       "      <td>Sioux City, Iowa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>also tuesday , health officials made public fo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>496</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri Jun 12 17:31:25 +0000 2020</td>\n",
       "      <td>2481913250</td>\n",
       "      <td>1271495332866568193</td>\n",
       "      <td>Vellore, Tamil Nadu, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bbc news coronavirus overwhelmed india hospita...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>554</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon Jun 15 00:03:18 +0000 2020</td>\n",
       "      <td>813086530390675456</td>\n",
       "      <td>1272318729695694849</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a seattle man received a 1 1 million bill for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>572</td>\n",
       "      <td>1</td>\n",
       "      <td>Sat Apr 25 07:31:09 +0000 2020</td>\n",
       "      <td>44290654</td>\n",
       "      <td>1253949653348802560</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>618 new covid 19 cases in singapore , taking t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>581</td>\n",
       "      <td>1</td>\n",
       "      <td>Wed Mar 04 20:24:14 +0000 2020</td>\n",
       "      <td>29130202</td>\n",
       "      <td>1235300039595085825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>am i wrong in questioning why la put out a sta...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>598</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri Jun 05 16:54:09 +0000 2020</td>\n",
       "      <td>245687754</td>\n",
       "      <td>1268949241101119489</td>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13 more people test covid19 positive in manipu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>602</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon Jun 15 02:08:12 +0000 2020</td>\n",
       "      <td>1073942939510956032</td>\n",
       "      <td>1272350163613474816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>global deaths due to various causes and covid ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>604</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue Feb 11 21:04:15 +0000 2020</td>\n",
       "      <td>2336351879</td>\n",
       "      <td>1227337577105149953</td>\n",
       "      <td>South East, England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>omg some chinese people are beating their dogs...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>610</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon Apr 27 21:05:24 +0000 2020</td>\n",
       "      <td>44785696</td>\n",
       "      <td>1254879340967407616</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i check the stats for the covid 19 numbers loo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>613</td>\n",
       "      <td>1</td>\n",
       "      <td>Thu Apr 02 22:10:54 +0000 2020</td>\n",
       "      <td>890256018231480320</td>\n",
       "      <td>1245836130290823169</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>these covid 19 numbers are horrific total infe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>618</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue May 19 00:25:01 +0000 2020</td>\n",
       "      <td>1242228801829928960</td>\n",
       "      <td>1262539724813553664</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>that s because he s not it s all nothing more ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>627</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri May 08 21:03:48 +0000 2020</td>\n",
       "      <td>2755986901</td>\n",
       "      <td>1258865208434364418</td>\n",
       "      <td>New York, USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>in belarus , world war ii victory parade will ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>662</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon May 18 18:56:51 +0000 2020</td>\n",
       "      <td>1015139262877044737</td>\n",
       "      <td>1262457139165093895</td>\n",
       "      <td>Uranus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>they are n't going there for covid19 treatment...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>663</td>\n",
       "      <td>1</td>\n",
       "      <td>Thu May 28 03:01:26 +0000 2020</td>\n",
       "      <td>587909086</td>\n",
       "      <td>1265840575867162624</td>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hydroxychloroquine again shows promise wake up...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>665</td>\n",
       "      <td>1</td>\n",
       "      <td>Wed May 27 13:03:40 +0000 2020</td>\n",
       "      <td>2883489013</td>\n",
       "      <td>1265629746941038601</td>\n",
       "      <td>Chennai, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6 deaths today , total covid 19 death toll in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>681</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue May 12 20:07:07 +0000 2020</td>\n",
       "      <td>785199901541937152</td>\n",
       "      <td>1260300494922186752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hydroxychloroquine works for the majority of t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>706</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun Jun 07 21:09:39 +0000 2020</td>\n",
       "      <td>62575859</td>\n",
       "      <td>1269738314501931020</td>\n",
       "      <td>St. Petersburg FL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>florida coronavirus cases top 1 , 000 for fift...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      2  predicted                      created_at         read_user_id  \\\n",
       "0    23          1  Fri Mar 27 18:03:15 +0000 2020            443692189   \n",
       "1    25          1  Fri May 01 02:04:45 +0000 2020            529055116   \n",
       "2    28          1  Wed Apr 15 19:33:55 +0000 2020            139283160   \n",
       "3    50          1  Tue Jun 16 01:25:11 +0000 2020   999766907468308481   \n",
       "4    67          1  Fri May 22 09:34:30 +0000 2020           4835434534   \n",
       "5   102          1  Mon Jun 08 21:01:38 +0000 2020             48769276   \n",
       "6   107          1  Tue May 19 21:04:44 +0000 2020  1240761596894416900   \n",
       "7   117          1  Thu Apr 23 09:17:13 +0000 2020            417553124   \n",
       "8   140          1  Sat May 30 20:50:36 +0000 2020             88661178   \n",
       "9   177          1  Sun Apr 26 03:25:02 +0000 2020             85035396   \n",
       "10  182          1  Sun May 10 04:34:17 +0000 2020   910586279871614977   \n",
       "11  186          1  Mon Apr 20 05:46:11 +0000 2020             21099818   \n",
       "12  194          1  Thu May 28 15:15:00 +0000 2020  1243652399727771651   \n",
       "13  203          1  Mon May 18 22:03:20 +0000 2020            270921976   \n",
       "14  215          1  Tue May 05 00:22:09 +0000 2020             19898168   \n",
       "15  236          1  Sat May 23 03:20:39 +0000 2020  1232104880220839937   \n",
       "16  246          1  Sun Apr 19 15:53:02 +0000 2020             70244885   \n",
       "17  259          1  Fri Apr 24 16:01:04 +0000 2020             79983391   \n",
       "18  280          1  Mon Apr 13 18:31:40 +0000 2020           2619163263   \n",
       "19  327          1  Sat Apr 18 10:51:39 +0000 2020            339277892   \n",
       "20  334          1  Sun Mar 08 11:28:07 +0000 2020            352875784   \n",
       "21  337          1  Mon Apr 27 07:23:04 +0000 2020           1096681020   \n",
       "22  374          1  Mon May 25 15:28:28 +0000 2020  1245009868563587073   \n",
       "23  387          1  Wed May 27 22:47:13 +0000 2020   966846014698283008   \n",
       "24  393          1  Tue May 26 02:32:34 +0000 2020  1084980649520496642   \n",
       "25  404          1  Mon Feb 17 18:15:28 +0000 2020   914746291753832448   \n",
       "26  405          1  Sat May 02 16:54:02 +0000 2020   971667390994903040   \n",
       "27  420          1  Wed Apr 29 17:17:13 +0000 2020             99710686   \n",
       "28  427          1  Mon Jun 01 12:13:27 +0000 2020            973724136   \n",
       "29  454          1  Thu Apr 30 09:02:06 +0000 2020  1114553046753792000   \n",
       "30  472          1  Thu May 07 02:25:06 +0000 2020             34677788   \n",
       "31  478          1  Wed Apr 22 00:28:58 +0000 2020            312045771   \n",
       "32  481          1  Thu Apr 09 06:17:00 +0000 2020             61788662   \n",
       "33  484          1  Wed May 06 14:58:01 +0000 2020             12663042   \n",
       "34  496          1  Fri Jun 12 17:31:25 +0000 2020           2481913250   \n",
       "35  554          1  Mon Jun 15 00:03:18 +0000 2020   813086530390675456   \n",
       "36  572          1  Sat Apr 25 07:31:09 +0000 2020             44290654   \n",
       "37  581          1  Wed Mar 04 20:24:14 +0000 2020             29130202   \n",
       "38  598          1  Fri Jun 05 16:54:09 +0000 2020            245687754   \n",
       "39  602          1  Mon Jun 15 02:08:12 +0000 2020  1073942939510956032   \n",
       "40  604          1  Tue Feb 11 21:04:15 +0000 2020           2336351879   \n",
       "41  610          1  Mon Apr 27 21:05:24 +0000 2020             44785696   \n",
       "42  613          1  Thu Apr 02 22:10:54 +0000 2020   890256018231480320   \n",
       "43  618          1  Tue May 19 00:25:01 +0000 2020  1242228801829928960   \n",
       "44  627          1  Fri May 08 21:03:48 +0000 2020           2755986901   \n",
       "45  662          1  Mon May 18 18:56:51 +0000 2020  1015139262877044737   \n",
       "46  663          1  Thu May 28 03:01:26 +0000 2020            587909086   \n",
       "47  665          1  Wed May 27 13:03:40 +0000 2020           2883489013   \n",
       "48  681          1  Tue May 12 20:07:07 +0000 2020   785199901541937152   \n",
       "49  706          1  Sun Jun 07 21:09:39 +0000 2020             62575859   \n",
       "\n",
       "          read_tweet_id                     user_location coordinates  \\\n",
       "0   1243599480177471489                  Hyderabad, India         NaN   \n",
       "1   1256041840807206914                     United States         NaN   \n",
       "2   1250507666956443651                               NaN         NaN   \n",
       "3   1272701725036679168                               NaN         NaN   \n",
       "4   1263765169055858688                    Abuja, Nigeria         NaN   \n",
       "5   1270098685628682242                               NaN         NaN   \n",
       "6   1262851706037194754                               NaN         NaN   \n",
       "7   1253251569253888000                        West Coast         NaN   \n",
       "8   1266834417600933895                           Nigeria         NaN   \n",
       "9   1254250103113691145                            🅱🅷🅰🆁🅰🆃         NaN   \n",
       "10  1259340963895369728           California, Kern County         NaN   \n",
       "11  1252111300265750528                   London, England         NaN   \n",
       "12  1266025183795707910                               NaN         NaN   \n",
       "13  1262504067881984000                            CANADA         NaN   \n",
       "14  1257465569588195329                               NaN         NaN   \n",
       "15  1264033473247031298                               NaN         NaN   \n",
       "16  1251901631098060800                               NaN         NaN   \n",
       "17  1253715591745212418               Lancashire, England         NaN   \n",
       "18  1249767225692549121             Christian/English USA         NaN   \n",
       "19  1251463398644166659                               NaN         NaN   \n",
       "20  1236614672112992258                     mumbai, india         NaN   \n",
       "21  1254672396168151041  Northern Ireland, United Kingdom         NaN   \n",
       "22  1264941410123427840                  Toronto, Ontario         NaN   \n",
       "23  1265776602530676736                               NaN         NaN   \n",
       "24  1265108539011485698                     New York City         NaN   \n",
       "25  1229469427512565769                               NaN         NaN   \n",
       "26  1256628025258467328          Scotland, United Kingdom         NaN   \n",
       "27  1255546694768513026                       Nowhere Boy         NaN   \n",
       "28  1267429046352261121                               NaN         NaN   \n",
       "29  1255784483132932096                     Melle, België         NaN   \n",
       "30  1258221289606709251                        New Jersey         NaN   \n",
       "31  1252756242826592256                       Oakland, CA         NaN   \n",
       "32  1248132788798144512      Port Moody, British Columbia         NaN   \n",
       "33  1258048378543509504                  Sioux City, Iowa         NaN   \n",
       "34  1271495332866568193        Vellore, Tamil Nadu, India         NaN   \n",
       "35  1272318729695694849                     United States         NaN   \n",
       "36  1253949653348802560                         Singapore         NaN   \n",
       "37  1235300039595085825                               NaN         NaN   \n",
       "38  1268949241101119489                  New Delhi, India         NaN   \n",
       "39  1272350163613474816                               NaN         NaN   \n",
       "40  1227337577105149953               South East, England         NaN   \n",
       "41  1254879340967407616                                           NaN   \n",
       "42  1245836130290823169                    Washington, DC         NaN   \n",
       "43  1262539724813553664                     United States         NaN   \n",
       "44  1258865208434364418                     New York, USA         NaN   \n",
       "45  1262457139165093895                           Uranus          NaN   \n",
       "46  1265840575867162624                      Florida, USA         NaN   \n",
       "47  1265629746941038601                    Chennai, India         NaN   \n",
       "48  1260300494922186752                               NaN         NaN   \n",
       "49  1269738314501931020                 St. Petersburg FL         NaN   \n",
       "\n",
       "                                                place  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8   {'id': '011a942e0a0e8fb2', 'url': 'https://api...   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "26                                                NaN   \n",
       "27                                                NaN   \n",
       "28  {'id': '6a1b0cb35bcaf140', 'url': 'https://api...   \n",
       "29                                                NaN   \n",
       "30                                                NaN   \n",
       "31                                                NaN   \n",
       "32  {'id': '55b2935da16ddb91', 'url': 'https://api...   \n",
       "33                                                NaN   \n",
       "34                                                NaN   \n",
       "35                                                NaN   \n",
       "36                                                NaN   \n",
       "37                                                NaN   \n",
       "38                                                NaN   \n",
       "39                                                NaN   \n",
       "40                                                NaN   \n",
       "41                                                NaN   \n",
       "42                                                NaN   \n",
       "43                                                NaN   \n",
       "44                                                NaN   \n",
       "45                                                NaN   \n",
       "46                                                NaN   \n",
       "47                                                NaN   \n",
       "48                                                NaN   \n",
       "49                                                NaN   \n",
       "\n",
       "                                     read_text_clean2  \\\n",
       "0   yet no , federal lockdown \\? \\? make america g...   \n",
       "1   cases of coronavirus has been climbing the las...   \n",
       "2   tennessee reports 256 new cases and 11 new dea...   \n",
       "3   well let s let oklahoma decide they don t have...   \n",
       "4   please don t be that dismissive of facts coron...   \n",
       "5   nyt breaking news new daily coronavirus cases ...   \n",
       "6   ohio usa northamerica cases 28 , 956 \\( 1 \\) d...   \n",
       "7   roberts failed to understand there are far mor...   \n",
       "8   america coming from a lockdown to utter chaos ...   \n",
       "9   total number of covid19 cases rise to 26 , 496...   \n",
       "10  the virology journal the official publication ...   \n",
       "11  help slow the spread of covid19 and identify a...   \n",
       "12  there have been 10 confirmed cases of covid19 ...   \n",
       "13  70 cases of covid 19 linked to french schools ...   \n",
       "14  coronavirus live updates global death toll top...   \n",
       "15  key words fraud , seriously ill covid 19 patie...   \n",
       "16  japanese hospitals overwhelmed as nation tops ...   \n",
       "17  during the covid 19 lockdown it s important to...   \n",
       "18  share to agree w no more to haters plotting ou...   \n",
       "19  united states coronavirus cases 710 , 272 deat...   \n",
       "20  singapore has recorded eight new cases of coro...   \n",
       "21  the issue is , if they fail to take action it ...   \n",
       "22  covid 19 today gt 14 , 570 , 000 people in ont...   \n",
       "23  interestingly , there has only been one death ...   \n",
       "24  pathological liar , corrupt criminal donaldtru...   \n",
       "25  chinese doctors 'using plasma therapy' on coro...   \n",
       "26  italy 's daily coronavirus death toll jumps , ...   \n",
       "27  early peek at data on gilead coronavirus drug ...   \n",
       "28  coronavirus dorset hospital death toll rises t...   \n",
       "29  we have finetuned our data flows , and are now...   \n",
       "30  covid 19 patients wrong to think breathing tub...   \n",
       "31  if only we could track the up to 10 of these f...   \n",
       "32  media just parrots that closing parks will hel...   \n",
       "33  also tuesday , health officials made public fo...   \n",
       "34  bbc news coronavirus overwhelmed india hospita...   \n",
       "35  a seattle man received a 1 1 million bill for ...   \n",
       "36  618 new covid 19 cases in singapore , taking t...   \n",
       "37  am i wrong in questioning why la put out a sta...   \n",
       "38  13 more people test covid19 positive in manipu...   \n",
       "39  global deaths due to various causes and covid ...   \n",
       "40  omg some chinese people are beating their dogs...   \n",
       "41  i check the stats for the covid 19 numbers loo...   \n",
       "42  these covid 19 numbers are horrific total infe...   \n",
       "43  that s because he s not it s all nothing more ...   \n",
       "44  in belarus , world war ii victory parade will ...   \n",
       "45  they are n't going there for covid19 treatment...   \n",
       "46  hydroxychloroquine again shows promise wake up...   \n",
       "47  6 deaths today , total covid 19 death toll in ...   \n",
       "48  hydroxychloroquine works for the majority of t...   \n",
       "49  florida coronavirus cases top 1 , 000 for fift...   \n",
       "\n",
       "    Perceived_susceptibility  Perceived_severity  Perceived_benefits  \\\n",
       "0                          1                   1                   0   \n",
       "1                          1                   0                   0   \n",
       "2                          1                   1                   0   \n",
       "3                          1                   0                   0   \n",
       "4                          1                   0                   0   \n",
       "5                          1                   1                   0   \n",
       "6                          1                   1                   0   \n",
       "7                          1                   1                   0   \n",
       "8                          1                   1                   0   \n",
       "9                          1                   0                   0   \n",
       "10                         0                   0                   1   \n",
       "11                         1                   0                   0   \n",
       "12                         1                   1                   0   \n",
       "13                         1                   0                   0   \n",
       "14                         1                   1                   0   \n",
       "15                         0                   0                   0   \n",
       "16                         1                   0                   0   \n",
       "17                         1                   1                   0   \n",
       "18                         0                   1                   0   \n",
       "19                         1                   1                   0   \n",
       "20                         1                   0                   0   \n",
       "21                         1                   1                   0   \n",
       "22                         1                   1                   0   \n",
       "23                         0                   1                   0   \n",
       "24                         1                   1                   0   \n",
       "25                         0                   0                   1   \n",
       "26                         1                   1                   0   \n",
       "27                         0                   0                   0   \n",
       "28                         0                   1                   0   \n",
       "29                         0                   0                   0   \n",
       "30                         0                   1                   0   \n",
       "31                         0                   1                   0   \n",
       "32                         1                   0                   0   \n",
       "33                         1                   0                   0   \n",
       "34                         0                   0                   0   \n",
       "35                         0                   0                   0   \n",
       "36                         1                   0                   0   \n",
       "37                         1                   0                   0   \n",
       "38                         1                   0                   0   \n",
       "39                         0                   1                   0   \n",
       "40                         0                   1                   0   \n",
       "41                         1                   0                   0   \n",
       "42                         1                   1                   0   \n",
       "43                         0                   0                   0   \n",
       "44                         1                   0                   0   \n",
       "45                         0                   0                   1   \n",
       "46                         0                   0                   0   \n",
       "47                         1                   1                   0   \n",
       "48                         0                   0                   1   \n",
       "49                         1                   0                   0   \n",
       "\n",
       "    Perceived_barriers       date  \n",
       "0                    0 2020-03-27  \n",
       "1                    0 2020-05-01  \n",
       "2                    0 2020-04-15  \n",
       "3                    0 2020-06-16  \n",
       "4                    0 2020-05-22  \n",
       "5                    0 2020-06-08  \n",
       "6                    0 2020-05-19  \n",
       "7                    0 2020-04-23  \n",
       "8                    0 2020-05-30  \n",
       "9                    0 2020-04-26  \n",
       "10                   0 2020-05-10  \n",
       "11                   0 2020-04-20  \n",
       "12                   0 2020-05-28  \n",
       "13                   0 2020-05-18  \n",
       "14                   0 2020-05-05  \n",
       "15                   0 2020-05-23  \n",
       "16                   0 2020-04-19  \n",
       "17                   0 2020-04-24  \n",
       "18                   0 2020-04-13  \n",
       "19                   0 2020-04-18  \n",
       "20                   0 2020-03-08  \n",
       "21                   0 2020-04-27  \n",
       "22                   0 2020-05-25  \n",
       "23                   0 2020-05-27  \n",
       "24                   0 2020-05-26  \n",
       "25                   0 2020-02-17  \n",
       "26                   0 2020-05-02  \n",
       "27                   0 2020-04-29  \n",
       "28                   0 2020-06-01  \n",
       "29                   0 2020-04-30  \n",
       "30                   0 2020-05-07  \n",
       "31                   0 2020-04-22  \n",
       "32                   0 2020-04-09  \n",
       "33                   0 2020-05-06  \n",
       "34                   0 2020-06-12  \n",
       "35                   0 2020-06-15  \n",
       "36                   0 2020-04-25  \n",
       "37                   0 2020-03-04  \n",
       "38                   0 2020-06-05  \n",
       "39                   0 2020-06-15  \n",
       "40                   0 2020-02-11  \n",
       "41                   0 2020-04-27  \n",
       "42                   0 2020-04-02  \n",
       "43                   1 2020-05-19  \n",
       "44                   0 2020-05-08  \n",
       "45                   0 2020-05-18  \n",
       "46                   1 2020-05-28  \n",
       "47                   0 2020-05-27  \n",
       "48                   0 2020-05-12  \n",
       "49                   0 2020-06-07  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data_formatted.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.675488789876302e-05\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "doc_clean = [clean_text(tweets, stop_words_list, exclude, lemma).split() for tweets in tweet_data_formatted['read_text_clean2']]\n",
    "\n",
    "end = time.time()\n",
    "print((end - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>predicted</th>\n",
       "      <th>created_at</th>\n",
       "      <th>read_user_id</th>\n",
       "      <th>read_tweet_id</th>\n",
       "      <th>user_location</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>place</th>\n",
       "      <th>read_text_clean2</th>\n",
       "      <th>Perceived_susceptibility</th>\n",
       "      <th>Perceived_severity</th>\n",
       "      <th>Perceived_benefits</th>\n",
       "      <th>Perceived_barriers</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri Mar 27 18:03:15 +0000 2020</td>\n",
       "      <td>443692189</td>\n",
       "      <td>1243599480177471489</td>\n",
       "      <td>Hyderabad, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yet no , federal lockdown \\? \\? make america g...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri May 01 02:04:45 +0000 2020</td>\n",
       "      <td>529055116</td>\n",
       "      <td>1256041840807206914</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cases of coronavirus has been climbing the las...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Wed Apr 15 19:33:55 +0000 2020</td>\n",
       "      <td>139283160</td>\n",
       "      <td>1250507666956443651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tennessee reports 256 new cases and 11 new dea...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue Jun 16 01:25:11 +0000 2020</td>\n",
       "      <td>999766907468308481</td>\n",
       "      <td>1272701725036679168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>well let s let oklahoma decide they don t have...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri May 22 09:34:30 +0000 2020</td>\n",
       "      <td>4835434534</td>\n",
       "      <td>1263765169055858688</td>\n",
       "      <td>Abuja, Nigeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>please don t be that dismissive of facts coron...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5585773</th>\n",
       "      <td>30611160</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon Feb 03 22:17:07 +0000 2020</td>\n",
       "      <td>25539652</td>\n",
       "      <td>1224456809420709890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>china's hubei province reports 64 coronavirus ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5585774</th>\n",
       "      <td>30611162</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun May 03 06:24:24 +0000 2020</td>\n",
       "      <td>1158447564036988928</td>\n",
       "      <td>1256831959902433282</td>\n",
       "      <td>Dontmesswith, Texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oh yee of such great intellect does this seem ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5585776</th>\n",
       "      <td>30611186</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri Apr 24 18:27:26 +0000 2020</td>\n",
       "      <td>456541283</td>\n",
       "      <td>1253752426714234880</td>\n",
       "      <td>Great USA.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>if you died in the hospital from say a heart a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5585777</th>\n",
       "      <td>30611187</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue May 26 18:24:37 +0000 2020</td>\n",
       "      <td>402409431</td>\n",
       "      <td>1265348129055838208</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>its wrong and risky for a president as a leade...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5585778</th>\n",
       "      <td>30611224</td>\n",
       "      <td>1</td>\n",
       "      <td>Sat May 16 05:48:09 +0000 2020</td>\n",
       "      <td>28088216</td>\n",
       "      <td>1261533877694115840</td>\n",
       "      <td>Chennai, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a sudden spike in the tirunelveli dis...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4309366 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                2  predicted                      created_at  \\\n",
       "0              23          1  Fri Mar 27 18:03:15 +0000 2020   \n",
       "1              25          1  Fri May 01 02:04:45 +0000 2020   \n",
       "2              28          1  Wed Apr 15 19:33:55 +0000 2020   \n",
       "3              50          1  Tue Jun 16 01:25:11 +0000 2020   \n",
       "4              67          1  Fri May 22 09:34:30 +0000 2020   \n",
       "...           ...        ...                             ...   \n",
       "5585773  30611160          1  Mon Feb 03 22:17:07 +0000 2020   \n",
       "5585774  30611162          1  Sun May 03 06:24:24 +0000 2020   \n",
       "5585776  30611186          1  Fri Apr 24 18:27:26 +0000 2020   \n",
       "5585777  30611187          1  Tue May 26 18:24:37 +0000 2020   \n",
       "5585778  30611224          1  Sat May 16 05:48:09 +0000 2020   \n",
       "\n",
       "                read_user_id        read_tweet_id        user_location  \\\n",
       "0                  443692189  1243599480177471489     Hyderabad, India   \n",
       "1                  529055116  1256041840807206914        United States   \n",
       "2                  139283160  1250507666956443651                  NaN   \n",
       "3         999766907468308481  1272701725036679168                  NaN   \n",
       "4                 4835434534  1263765169055858688       Abuja, Nigeria   \n",
       "...                      ...                  ...                  ...   \n",
       "5585773             25539652  1224456809420709890                  NaN   \n",
       "5585774  1158447564036988928  1256831959902433282  Dontmesswith, Texas   \n",
       "5585776            456541283  1253752426714234880           Great USA.   \n",
       "5585777            402409431  1265348129055838208        United States   \n",
       "5585778             28088216  1261533877694115840       Chennai, India   \n",
       "\n",
       "        coordinates place                                   read_text_clean2  \\\n",
       "0               NaN   NaN  yet no , federal lockdown \\? \\? make america g...   \n",
       "1               NaN   NaN  cases of coronavirus has been climbing the las...   \n",
       "2               NaN   NaN  tennessee reports 256 new cases and 11 new dea...   \n",
       "3               NaN   NaN  well let s let oklahoma decide they don t have...   \n",
       "4               NaN   NaN  please don t be that dismissive of facts coron...   \n",
       "...             ...   ...                                                ...   \n",
       "5585773         NaN   NaN  china's hubei province reports 64 coronavirus ...   \n",
       "5585774         NaN   NaN  oh yee of such great intellect does this seem ...   \n",
       "5585776         NaN   NaN  if you died in the hospital from say a heart a...   \n",
       "5585777         NaN   NaN  its wrong and risky for a president as a leade...   \n",
       "5585778         NaN   NaN  there is a sudden spike in the tirunelveli dis...   \n",
       "\n",
       "         Perceived_susceptibility  Perceived_severity  Perceived_benefits  \\\n",
       "0                               1                   1                   0   \n",
       "1                               1                   0                   0   \n",
       "2                               1                   1                   0   \n",
       "3                               1                   0                   0   \n",
       "4                               1                   0                   0   \n",
       "...                           ...                 ...                 ...   \n",
       "5585773                         0                   1                   0   \n",
       "5585774                         1                   1                   0   \n",
       "5585776                         0                   1                   0   \n",
       "5585777                         1                   1                   0   \n",
       "5585778                         1                   0                   0   \n",
       "\n",
       "         Perceived_barriers       date  \n",
       "0                         0 2020-03-27  \n",
       "1                         0 2020-05-01  \n",
       "2                         0 2020-04-15  \n",
       "3                         0 2020-06-16  \n",
       "4                         0 2020-05-22  \n",
       "...                     ...        ...  \n",
       "5585773                   0 2020-02-03  \n",
       "5585774                   0 2020-05-03  \n",
       "5585776                   0 2020-04-24  \n",
       "5585777                   0 2020-05-26  \n",
       "5585778                   0 2020-05-16  \n",
       "\n",
       "[4309366 rows x 14 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['yet', 'federal', 'lockdown', 'make', 'america', 'great', 'death'],\n",
       " ['case',\n",
       "  'coronavirus',\n",
       "  'climbing',\n",
       "  'last',\n",
       "  'three',\n",
       "  'day',\n",
       "  'across',\n",
       "  'country',\n",
       "  'ready',\n",
       "  'reopen',\n",
       "  'anything']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary, doc_term_matrix = create_dictionary(doc_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**```time_seq``` should split the data by time (days, months, years)**\n",
    "\n",
    "For this analysis, we will split by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>predicted</th>\n",
       "      <th>created_at</th>\n",
       "      <th>read_user_id</th>\n",
       "      <th>read_tweet_id</th>\n",
       "      <th>user_location</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>place</th>\n",
       "      <th>read_text_clean2</th>\n",
       "      <th>Perceived_susceptibility</th>\n",
       "      <th>Perceived_severity</th>\n",
       "      <th>Perceived_benefits</th>\n",
       "      <th>Perceived_barriers</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5350479</th>\n",
       "      <td>26701110</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon Jan 06 14:54:46 +0000 2020</td>\n",
       "      <td>382391949</td>\n",
       "      <td>1214198629553950721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tldr not sars , possibly new coronavirus diffi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465576</th>\n",
       "      <td>26465365</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri Jan 10 13:25:20 +0000 2020</td>\n",
       "      <td>733491445798162432</td>\n",
       "      <td>1215625674376937473</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cdc health advisory about the chinese coronavi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881234</th>\n",
       "      <td>16746947</td>\n",
       "      <td>1</td>\n",
       "      <td>Sat Jan 11 08:09:14 +0000 2020</td>\n",
       "      <td>4134073822</td>\n",
       "      <td>1215908513064607745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>china reports 1st death from 'new type of coro...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360846</th>\n",
       "      <td>5987839</td>\n",
       "      <td>1</td>\n",
       "      <td>Sat Jan 11 14:00:11 +0000 2020</td>\n",
       "      <td>100986964</td>\n",
       "      <td>1215996832515530752</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>china reports first death from new coronavirus...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206380</th>\n",
       "      <td>5541744</td>\n",
       "      <td>1</td>\n",
       "      <td>Mon Jan 13 17:02:28 +0000 2020</td>\n",
       "      <td>1270238612</td>\n",
       "      <td>1216767481383137280</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good news on wuhan coronavirus rpts outbreak h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                2  predicted                      created_at  \\\n",
       "5350479  26701110          1  Mon Jan 06 14:54:46 +0000 2020   \n",
       "3465576  26465365          1  Fri Jan 10 13:25:20 +0000 2020   \n",
       "2881234  16746947          1  Sat Jan 11 08:09:14 +0000 2020   \n",
       "360846    5987839          1  Sat Jan 11 14:00:11 +0000 2020   \n",
       "2206380   5541744          1  Mon Jan 13 17:02:28 +0000 2020   \n",
       "\n",
       "               read_user_id        read_tweet_id   user_location coordinates  \\\n",
       "5350479           382391949  1214198629553950721             NaN         NaN   \n",
       "3465576  733491445798162432  1215625674376937473      Boston, MA         NaN   \n",
       "2881234          4134073822  1215908513064607745             NaN         NaN   \n",
       "360846            100986964  1215996832515530752             USA         NaN   \n",
       "2206380          1270238612  1216767481383137280  Washington, DC         NaN   \n",
       "\n",
       "        place                                   read_text_clean2  \\\n",
       "5350479   NaN  tldr not sars , possibly new coronavirus diffi...   \n",
       "3465576   NaN  cdc health advisory about the chinese coronavi...   \n",
       "2881234   NaN  china reports 1st death from 'new type of coro...   \n",
       "360846    NaN  china reports first death from new coronavirus...   \n",
       "2206380   NaN  good news on wuhan coronavirus rpts outbreak h...   \n",
       "\n",
       "         Perceived_susceptibility  Perceived_severity  Perceived_benefits  \\\n",
       "5350479                         0                   0                   0   \n",
       "3465576                         0                   1                   0   \n",
       "2881234                         0                   1                   0   \n",
       "360846                          0                   1                   0   \n",
       "2206380                         1                   0                   0   \n",
       "\n",
       "         Perceived_barriers       date  \n",
       "5350479                   0 2020-01-06  \n",
       "3465576                   0 2020-01-10  \n",
       "2881234                   0 2020-01-11  \n",
       "360846                    0 2020-01-11  \n",
       "2206380                   0 2020-01-13  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data_formatted = tweet_data_formatted.sort_values('date')\n",
    "tweet_data_formatted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort by day\n",
    "#time_seq = tweet_data_formatted[['read_text_clean2', 'date']].groupby(['date'], as_index=False).agg(['count']).reset_index()\n",
    "\n",
    "# sort by month\n",
    "time_seq = tweet_data_formatted[['read_text_clean2', 'date']].groupby(pd.Grouper(key='date', freq='1M')).agg('count') # groupby each 1 month\n",
    "time_seq = time_seq.reset_index()\n",
    "time_seq = time_seq['read_text_clean2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      46843\n",
       "1     200078\n",
       "2     679424\n",
       "3    1231986\n",
       "4    1359403\n",
       "5     791632\n",
       "Name: read_text_clean2, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(topic_term, top_k):\n",
    "    topic_term = np.exp(topic_term)\n",
    "    topic_term = topic_term / topic_term.sum()\n",
    "    topic_term = topic_term * top_k\n",
    "    return topic_term\n",
    "\n",
    "def get_topics(topic_terms, topic_number):\n",
    "    topic_terms = topic_terms[topic_number]\n",
    "    bestn = matutils.argsort(topic_terms, 20, reverse=True)\n",
    "    beststr = [dictionary[id_] for id_ in bestn]\n",
    "    return beststr\n",
    "\n",
    "# next is the vocabulary, which we already have\n",
    "vocab = []\n",
    "for i in range(0, len(dictionary)):\n",
    "    vocab.append(dictionary[i])\n",
    "\n",
    "# we now need term-frequency and doc_lengths\n",
    "\n",
    "def term_frequency(doc_term_matrix, dictionary):\n",
    "    term_frequency = [0] * len(dictionary)\n",
    "    doc_lengths = []\n",
    "    for doc in doc_term_matrix:\n",
    "        doc_lengths.append(len(doc))\n",
    "        for pair in doc:\n",
    "            term_frequency[pair[0]] += pair[1]\n",
    "    return term_frequency, doc_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod 755 -R '/home/mrh1996/LDA_COVID_Tweets/dtm-linux64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554.4876468539238\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "cov_model = DtmModel('/home/mrh1996/LDA_COVID_Tweets/dtm-linux64', doc_term_matrix, time_seq, num_topics=4,\n",
    "                             id2word=dictionary, initialize_lda=True, rng_seed = 82121)\n",
    "\n",
    "end = time.time()\n",
    "print((end - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrh1996/.conda/envs/lda_covid_tweets/lib/python3.6/site-packages/gensim/models/wrappers/dtmmodel.py:498: UserWarning: The parameter `num_words` is deprecated, will be removed in 4.0.0, use `topn` instead.\n",
      "  warnings.warn(\"The parameter `num_words` is deprecated, will be removed in 4.0.0, use `topn` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36806897761694946\n",
      "0.36806897761694946\n",
      "0.36806897761694946\n",
      "0.3728567665167569\n",
      "0.37074662496564886\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i in range(0, (len(time_seq)-1)):\n",
    "    coherence_topics = cov_model.dtm_coherence(time=i)\n",
    "    cm_wrapper_cv = CoherenceModel(topics=coherence_topics, texts=doc_clean, dictionary=dictionary, coherence='c_v')\n",
    "    score = cm_wrapper_cv.get_coherence()\n",
    "    print(score)\n",
    "    tup = 11, i, score\n",
    "    results.append(tup)\n",
    "\n",
    "lda_results = pd.DataFrame(results, columns=['topic', 'time', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "cov_model.save(fname_or_handle = '4_topics_dups_removed') #separately=None, sep_limit=10485760, ignore=frozenset([]), pickle_protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"doc_term_matrix_500000.txt\", \"wb\") as fp:\n",
    "  pickle.dump(doc_term_matrix, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
